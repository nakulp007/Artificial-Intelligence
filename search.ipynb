{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Graph Search\n",
    "In this assignment you will be implementing a variety of graph search algorithms, with the eventual goal of solving tridirectional search.\n",
    "\n",
    "Before you start, you will need to install:\n",
    "\n",
    "1. [networkx](http://networkx.github.io/), which is a package for processing networks. This assignment will be easier if you take some time to test out and get familiar with the [basic methods](https://networkx.github.io/examples.html) of networkx.\n",
    "\n",
    "2. [matplotlib](http://matplotlib.org/downloads.html) for basic network visualization.\n",
    "\n",
    "We will be using two undirected networks for this assignment: a simplified map of Romania (from Russell and Norvig) and a full street map of Atlanta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('lib')\n",
    "import networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Romania map data from Russell and Norvig, Chapter 3.\"\"\"\n",
    "romania = pickle.load(open('romania_graph.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmups\n",
    "------\n",
    "We'll start by implementing some simpler search and optimization methods before the real exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmup 1: Priority queue\n",
    "----------------------\n",
    "5 points\n",
    "\n",
    "In all searches that involve calculating path cost or heuristic (e.g. uniform-cost), we have to order our search frontier. It turns out the way that we do this can impact our overall search runtime. \n",
    "\n",
    "To show this, you'll implement a [priority queue](https://en.wikipedia.org/wiki/Priority_queue) and demonstrate its performance benefits. For large graphs, sorting all input to a priority queue is impractical. As such, the datastructure you implement should have an amortized O(1) insertion and removal time. It should do better than the queue you've been provided in InsertionSortQueue().\n",
    "\n",
    "Hints: \n",
    "1. The [heapq](https://docs.python.org/2/library/heapq.html) module has been imported for you.\n",
    "2. Each edge has an associated weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class PriorityQueue():\n",
    "    \"\"\"Implementation of a priority queue\n",
    "    to store nodes during search.\"\"\"\n",
    "    # TODO: finish this class\n",
    "\n",
    "    # HINT look up the module heapq.\n",
    "\n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "        self.current = 0\n",
    "        self.path = []\n",
    "        self.cost = 0\n",
    "\n",
    "    def next(self):\n",
    "        if self.current >=len(self.queue):\n",
    "            self.current\n",
    "            raise StopIteration\n",
    "\n",
    "        out = self.queue[self.current]\n",
    "        self.current += 1\n",
    "\n",
    "        return out\n",
    "\n",
    "    def pop(self):\n",
    "        # TODO: finish this\n",
    "        self.current -= 1\n",
    "        return heapq.heappop(self.queue)\n",
    "\n",
    "    def get(self):\n",
    "        return heapq.heappop(self.queue)[1]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'PQ:[%s]'%(', '.join([str(i) for i in self.queue]))\n",
    "\n",
    "    def append(self, node):\n",
    "        # TODO: finish this\n",
    "        heapq.heappush(self.queue,(node))\n",
    "        self.current += 1\n",
    "\n",
    "    def push(self, cost,node,path):\n",
    "        # TODO: finish this\n",
    "        self.cost = cost\n",
    "        self.path = path\n",
    "        heapq.heappush(self.queue,(self.cost,node,self.path))\n",
    "        self.current += 1\n",
    "\n",
    "    def put(self, item, priority):\n",
    "        heapq.heappush(self.queue, (priority, item))\n",
    "\n",
    "    def empty(self):\n",
    "        return len(self.queue) == 0\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        #self.current = 0\n",
    "        return key in [n for v,n in self.queue]\n",
    "\n",
    "    def astarContains(self, key):\n",
    "        #self.current = 0\n",
    "        return key in [y for x,y,z in self.queue]\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self == other\n",
    "\n",
    "    def clear(self):\n",
    "        self.queue = []\n",
    "\n",
    "    def has_element(self):\n",
    "        if len(self.queue) > 0:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    __next__ = next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PriorityQueue tests passed\n"
     ]
    }
   ],
   "source": [
    "from search_tests import priority_queue_tests\n",
    "\n",
    "priority_queue_tests(PriorityQueue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Warm-up 2: BFS\n",
    "----------\n",
    "5 pts\n",
    "\n",
    "To get you started with handling graphs in networkx, implement and test breadth-first search over the test network. You'll do this by writing two methods: \n",
    "1. breadth_first_search_goal, which returns the goal node and the set of all nodes explored, but no path.\n",
    "2. breadth_first_search, which returns the path and the set of all nodes explored.\n",
    "\n",
    "Hint: networkx.edges() will return all edges connected to a given node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " pathes = pickle.load(open('romania_test_paths.pickle', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 't', 'l', 'm'], ['a', 's', 'z', 't', 'r', 'o', 'f', 'l'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathes[('a', 'm')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pq.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def breadth_first_search_goal(graph, start, goal):\n",
    "    \"\"\"Run a breadth-first search from start\n",
    "    to goal and return the goal as well as\n",
    "    all nodes explored.\"\"\"\n",
    "    if start == goal: return None\n",
    "    frontier = [start]\n",
    "    explored = []\n",
    "\n",
    "    while len(frontier) != 0:\n",
    "        cur_node = frontier.pop(0)\n",
    "        explored.append(cur_node)\n",
    "        neighbours = graph.neighbors(cur_node)\n",
    "        for neighbour in neighbours:\n",
    "            if (neighbour not in explored) and (neighbour not in frontier):\n",
    "                frontier.append(neighbour)\n",
    "                if (neighbour == goal):\n",
    "                    neighbour = goal\n",
    "                    frontier[:] = []\n",
    "    \n",
    "    return goal, explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def breadth_first_search(graph, start, goal):\n",
    "    \"\"\"Run a breadth-first search from start\n",
    "    to goal and return the path as well as \n",
    "    all nodes explored.\"\"\"\n",
    "    if start == goal: return [],[]\n",
    "    frontier = [start]\n",
    "    explored = []\n",
    "    path = []\n",
    "    while len(frontier) != 0:\n",
    "        cur_node = frontier.pop(0)\n",
    "        explored.append(cur_node)\n",
    "        neighbours = graph.neighbors(cur_node)\n",
    "        for neighbour in neighbours:\n",
    "            if (neighbour not in explored) and (neighbour not in frontier):\n",
    "                if(neighbour == goal):\n",
    "                    return pathFinder(graph, start, goal),explored\n",
    "                else:\n",
    "                    frontier.append(neighbour)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pathFinder(graph, start, goal):\n",
    "     # Finding the path\n",
    "    path_queue = [start]\n",
    "    path = []\n",
    "    while len(path_queue) != 0:\n",
    "            path = path_queue.pop(0)\n",
    "            cur_node = path[-1]\n",
    "            if (cur_node == goal): return path\n",
    "            neighbours = graph.neighbors(cur_node)\n",
    "            for neighbour in neighbours:\n",
    "                updated_path = list(path)\n",
    "                updated_path.append(neighbour)\n",
    "                #print updated_path\n",
    "                path_queue.append(updated_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function exists to help you visually debug your code.\n",
    "# Feel free to modify it in any way you like.\n",
    "# graph should be a networkx graph\n",
    "# node_positions should be a dictionary mapping nodes to x,y coordinates\n",
    "def draw_graph(graph, node_positions={}, start=None, goal=None, explored=[], path=[]):\n",
    "\n",
    "    if not node_positions:\n",
    "        node_positions = networkx.spring_layout(graph)\n",
    "\n",
    "    networkx.draw_networkx_nodes(graph, node_positions)\n",
    "    networkx.draw_networkx_edges(graph, node_positions, style='dashed')\n",
    "    \n",
    "    networkx.draw_networkx_nodes(graph, node_positions, nodelist=explored, node_color='g') \n",
    "\n",
    "    if path:\n",
    "        edges = [(path[i], path[i+1]) for i in range(0, len(path)-1)]\n",
    "        networkx.draw_networkx_edges(graph, node_positions, edgelist=edges, edge_color='b')\n",
    "   \n",
    "    if start:\n",
    "        networkx.draw_networkx_nodes(graph, node_positions, nodelist=[start], node_color='b')\n",
    "    \n",
    "    if goal:\n",
    "        networkx.draw_networkx_nodes(graph, node_positions, nodelist=[goal], node_color='y')\n",
    "    \n",
    "    labels={}\n",
    "    for node in romania.nodes():\n",
    "        labels[node] = node\n",
    "    networkx.draw_networkx_labels(graph,node_positions,labels,font_size=16)\n",
    "    plt.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'u', 'b', 'f', 's']\n",
      "['h', 'u', 'e', 'b', 'v', 'p', 'g', 'f']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['h', 'u', 'b', 'f', 's'], ['h', 'u', 'e', 'b', 'v', 'p', 'g', 'f'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, explored = breadth_first_search(romania, 'h', 's') \n",
    "print path\n",
    "print explored\n",
    "pathes[('h', 's')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Testing and visualizing breadth-first search\n",
    "in the notebook.\"\"\"\n",
    "start = 'h'\n",
    "goal = 's'\n",
    "#%debug\n",
    "#%debug --breakpoint search_tests.py:58\n",
    "#%run -d\n",
    "goal, explored = breadth_first_search_goal(romania, start, goal) \n",
    "path, explored = breadth_first_search(romania, start, goal) \n",
    "node_locations = {n: romania.node[n]['position'] for n in romania.node.keys()}\n",
    "draw_graph(romania, node_locations, start, goal, explored, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'u', 'e', 'b', 'v', 'p', 'g', 'f']\n",
      "['h', 'u', 'b', 'f', 's']\n"
     ]
    }
   ],
   "source": [
    "print explored\n",
    "print path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS tests passed.\n"
     ]
    }
   ],
   "source": [
    "from search_tests import bfs_tests\n",
    "\n",
    "bfs_tests(breadth_first_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmup 3: Uniform-cost search\n",
    "----------------------------\n",
    "10 points\n",
    "\n",
    "Implement uniform-cost search using PriorityQueue() as your frontier. From now on, PriorityQueue() should be your default frontier. \n",
    "\n",
    "uniform_cost_search() should return the same arguments as breadth-first search: the path to the goal node, the set of all nodes explored, and the total cost of the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniform_cost_search(graph, start, goal):\n",
    "    \"\"\"Run uniform-cost search from start\n",
    "    to goal and return the path, the nodes\n",
    "    explored, and the total cost.\"\"\"\n",
    "    # TODO: finish this function\n",
    "    if start == goal: return [],[],0\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.push(0,start,[]) #frontier.append(cost,node,path)\n",
    "    explored = {}\n",
    " \n",
    "    while frontier.has_element():\n",
    "        \n",
    "        cost,node,path = frontier.pop()\n",
    "        \n",
    "        if (len(explored) > 0):\n",
    "            if (explored.has_key(node)) and (explored[node]<cost):\n",
    "                continue\n",
    "\n",
    "        path = path + [node]\n",
    "        \n",
    "   \n",
    "        neighbours = graph.edges(node)\n",
    "        for child in neighbours:\n",
    "            child_node = child[1]\n",
    "            child_cost = graph.edge[node][child_node]['weight']\n",
    "            if child_node not in explored: \n",
    "                frontier.push(cost + child_cost,child_node,path)\n",
    "                if child_node == goal:\n",
    "                    #if path[0] == 'z' and path[-1] == 'h':\n",
    "                        #print path\n",
    "                    return path,list(explored.keys()),cost\n",
    "        explored[node] = cost \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform cost search tests passed\n"
     ]
    }
   ],
   "source": [
    "from search_tests import ucs_tests\n",
    "ucs_tests(uniform_cost_search)\n",
    "#pathes[('z', 'h')][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmup 4: A\\* search\n",
    "------------------\n",
    "10 points\n",
    "\n",
    "Implement A\\* search using Euclidean distance as your heuristic. You'll need to implement heuristic_euclid() then pass that function to a_star() as the heuristic parameter. We provide null_heuristic() as a baseline heuristic to test against when calling a_star_tests()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 492)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romania.edge['a']['s']['weight']\n",
    "romania.node['a']['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_heuristic(graph, u, v, goal):\n",
    "    \"\"\"Return 0 for all nodes.\"\"\"\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heuristic_euclid(graph, u, v, goal):\n",
    "    \"\"\"Return the Euclidean distance from\n",
    "    the node to the goal. u is current node,\n",
    "    v is node under consideration.\"\"\"\n",
    "    import math\n",
    "    return math.sqrt( (graph.node[goal]['position'][0] - graph.node[v]['position'][0])**2 +  (graph.node[goal]['position'][1] - graph.node[v]['position'][1])**2  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def a_star(graph, start, goal, heuristic):\n",
    "    \"\"\"Run A* search from the start to\n",
    "    goal using the specified heuristic\n",
    "    function, and return the final path\n",
    "    and the nodes explored.\"\"\"\n",
    "    \n",
    "    def reconstruct_path(came_from, start, goal):\n",
    "        if start == goal:\n",
    "            return []\n",
    "        current = goal\n",
    "        path = [current]\n",
    "        while current != start:\n",
    "            current = came_from[current]\n",
    "            path.append(current)\n",
    "        path.reverse()\n",
    "        return path\n",
    "\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.put(start, 0)\n",
    "    came_from = {}\n",
    "    cost_so_far = {}\n",
    "    came_from[start] = None\n",
    "    cost_so_far[start] = 0\n",
    "    explored = [start]\n",
    "\n",
    "    while not frontier.empty():\n",
    "        current = frontier.get()\n",
    "\n",
    "        if current not in explored:\n",
    "            explored.append(current)\n",
    "\n",
    "        if current == goal:\n",
    "            break\n",
    "\n",
    "        for next in graph.neighbors(current):\n",
    "            new_cost = cost_so_far[current] + graph.edge[current][next]['weight']\n",
    "            if next not in cost_so_far or new_cost < cost_so_far[next]:\n",
    "                cost_so_far[next] = new_cost\n",
    "                priority = new_cost + heuristic(graph, current, next, goal)\n",
    "                frontier.put(next, priority)\n",
    "                came_from[next] = current\n",
    "\n",
    "    return reconstruct_path(came_from, start, goal), explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A star null_heuristic search tests passed\n",
      "A star euclidean_dist_heuristic search tests passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['z', 'a', 's', 'f', 'b', 'u', 'h'],\n",
       " ['z', 'a', 'o', 's', 't', 'r', 'f', 'l', 'p', 'c', 'b', 'm', 'd', 'u'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from search_tests import a_star_tests\n",
    "\n",
    "#%debug\n",
    "a_star_tests(a_star, null_heuristic, heuristic_euclid)\n",
    "pathes[('z', 'h')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "-------\n",
    "\n",
    "The following exercises will require you to implement several kinds of bidirectional and tridirectional searches.\n",
    "\n",
    "For the following exercises, we will be using Atlanta [OpenStreetMap](wiki.openstreetmap.org/) data for our searches. If you want to run tests in iPython notebook using this data (rather than just calling the tests in search_tests), you'll need to load the data from file in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Loading Atlanta map data.\"\"\"\n",
    "atlanta = pickle.load(open('atlanta_osm.pickle','r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing search results\n",
    "---\n",
    "\n",
    "When using a geographic network, you may want to visualize your searches. We can do this by converting the search results to a [GeoJSON](https://en.wikipedia.org/wiki/GeoJSON) file which we then visualize on [Gist](https://gist.github.com/) by [importing](https://github.com/blog/1576-gist-meets-geojson) the file.\n",
    "\n",
    "We provide a method for doing this in visualize_graph.py called plot_search(), which takes as parameters the graph, the name of the file to write, the nodes on the path, and the set of all nodes explored. This produces a GeoJSON file named as specified, which you can upload to Gist to visualize the search path and explored nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bidirectional_ucs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-996cf0d204fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m with two sample nodes in Atlanta.\"\"\"\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mvisualize_graph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_search\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplored\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbidirectional_ucs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0matlanta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'69244359'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'557989279'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplot_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'atlanta_search.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplored\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# then upload 'atlanta_search.json' to Gist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bidirectional_ucs' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Example of how to visualize search results\n",
    "with two sample nodes in Atlanta.\"\"\"\n",
    "from visualize_graph import plot_search\n",
    "path, explored = bidirectional_ucs(atlanta, '69244359', '557989279')\n",
    "plot_search(graph, 'atlanta_search.json', path, explored)\n",
    "# then upload 'atlanta_search.json' to Gist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: Bidirectional uniform-cost search\n",
    "-------\n",
    "15 points\n",
    "\n",
    "Implement bidirectional uniform-cost search. Remember that this requires starting your search at both the start and end states.\n",
    "\n",
    "This function will return the goal, the set of explored nodes from the start node's search, and the set of explored nodes from the goal node's search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bidirectional_ucs(graph, start, goal):\n",
    "    \"\"\"Run bidirectional uniform-cost search\n",
    "    between start and goal, and return the path,\n",
    "    the nodes explored from start-initial\n",
    "    search, and the nodes explored from the\n",
    "    goal-initial search.\"\"\"\n",
    "    import copy\n",
    "    from itertools import groupby\n",
    "\n",
    "    def remove_dups(lst):\n",
    "        return [k for k,items in groupby(lst)]\n",
    "\n",
    "    def getCost(graph, path):\n",
    "        cost = 0\n",
    "        prevNode = \"yolo\"\n",
    "        for i in path:\n",
    "            if prevNode == \"yolo\":\n",
    "                prevNode = i\n",
    "            else:\n",
    "                cost += graph.edge[prevNode][i]['weight']\n",
    "                prevNode = i\n",
    "        return cost\n",
    "\n",
    "    def getPath(child, goal, goal_paths):\n",
    "        if child == goal:\n",
    "            return []\n",
    "        path = [child]\n",
    "        while path[-1] != goal:\n",
    "            path.append(goal_paths[path[-1]])\n",
    "        return path\n",
    "\n",
    "\n",
    "    def build_next_level(paths, frontier, explored, graph, goal):\n",
    "        p = copy.deepcopy(paths)\n",
    "        ex = copy.deepcopy(explored)\n",
    "        mf = copy.deepcopy(frontier)\n",
    "        cost, node, path = mf.pop()\n",
    "\n",
    "        for child_node in graph.neighbors(node):\n",
    "            #child_node = child[1]\n",
    "            child_cost = graph.edge[node][child_node]['weight']\n",
    "\n",
    "            if (child_node not in ex and (child_node not in p or ex[p[child_node]] + graph.edge[p[child_node]][child_node]['weight'] > cost + child_cost)) or (child_node in ex and ex[child_node] > cost + child_cost):\n",
    "                mf.push(cost + child_cost,child_node,path + [child_node])\n",
    "                p[child_node] = node\n",
    "\n",
    "        ex[node] = cost\n",
    "        return p, mf, ex\n",
    "\n",
    "    if start == goal:\n",
    "            return [],([],[])\n",
    "\n",
    "    #if they are neighbors\n",
    "    if graph.neighbors(start).__contains__(goal):\n",
    "        return [start,goal], ([start,goal],[goal,start])\n",
    "\n",
    "    middleNodes = []\n",
    "    start_paths = { start:None } # node:parent\n",
    "    goal_paths = { goal:None }\n",
    "\n",
    "    startFrontier = PriorityQueue()\n",
    "    startFrontier.push(0,start,[]) #cost, node, path\n",
    "    goalFrontier = PriorityQueue()\n",
    "    goalFrontier.push(0,goal,[]) #cost, node, path\n",
    "    #start_last_level = [start]\n",
    "    #goal_last_level = [goal]\n",
    "\n",
    "    sExplored = {}\n",
    "    gExplored = {}\n",
    "\n",
    "    while startFrontier.has_element() and goalFrontier.has_element():\n",
    "        # get shared nodes\n",
    "        startNodes = set(sExplored.keys())\n",
    "        goalNodes = set(gExplored.keys())\n",
    "        middleNodes = startNodes.intersection(goalNodes)\n",
    "        if middleNodes: break\n",
    "\n",
    "\n",
    "        # build next level/depth decide on which to expand\n",
    "        sCost, sNode, sPath = startFrontier.pop()\n",
    "        startFrontier.push(sCost, sNode, sPath)\n",
    "        gCost, gNode, gPath = goalFrontier.pop()\n",
    "        goalFrontier.push(gCost, gNode, gPath)\n",
    "\n",
    "        if sCost <= gCost: #expand from start side\n",
    "            start_paths, startFrontier, sExplored = build_next_level(start_paths, startFrontier, sExplored, graph, goal)\n",
    "        else:\n",
    "            goal_paths, goalFrontier, gExplored = build_next_level(goal_paths, goalFrontier, gExplored, graph, goal)\n",
    "    else: # exited without break, empty path\n",
    "        return [],([],[])\n",
    "\n",
    "    # build the result\n",
    "\n",
    "    middle = list(middleNodes)[0]\n",
    "    #from middle to a\n",
    "    res = []\n",
    "    c = middle\n",
    "    while c != start:\n",
    "        c = start_paths[c]\n",
    "        res.insert(0,c)\n",
    "\n",
    "    res.append(middle)\n",
    "\n",
    "    #from middle to b\n",
    "    c = middle\n",
    "    while c != goal:\n",
    "        c = goal_paths[c]\n",
    "        res.append(c)\n",
    "\n",
    "    #look for shortcut\n",
    "    #res is original path\n",
    "    while startFrontier.has_element():\n",
    "        cost, node, path = startFrontier.pop()\n",
    "        if gExplored.__contains__(node):\n",
    "            tempPath = [start]\n",
    "            tempPath.extend(path)\n",
    "            tempPath.extend(getPath(node, goal,goal_paths))\n",
    "            tempPath = remove_dups(tempPath)\n",
    "            tempCost = cost + gExplored[node]\n",
    "            oCost = getCost(graph, remove_dups(res))\n",
    "            if tempCost < oCost:\n",
    "                res = tempPath\n",
    "\n",
    "    return res, (sExplored,gExplored)\n",
    "    #return path, (start_explored, goal_explored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works in IDE for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-0ec8ef445d27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msearch_tests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbidirectional_tests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbidirectional_tests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbidirectional_ucs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Nakul\\OneDrive\\Documents\\CS 6601 AI\\HW\\assignment_2\\search_tests.pyc\u001b[0m in \u001b[0;36mbidirectional_tests\u001b[1;34m(bidirectional_ucs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m             \u001b[0mpath_is_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_path_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mromania\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mget_path_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mromania\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_is_valid\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnode_exploration_valid\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath_is_correct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Nakul\\OneDrive\\Documents\\CS 6601 AI\\HW\\assignment_2\\search_tests.pyc\u001b[0m in \u001b[0;36mget_path_cost\u001b[1;34m(graph, path)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0medge_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_edge_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "from search_tests import bidirectional_tests\n",
    "\n",
    "bidirectional_tests(bidirectional_ucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: Bidirectional A\\* search\n",
    "-------\n",
    "20 points\n",
    "\n",
    "Implement bidirectional A\\* search. Remember that you need to calculate a heuristic for both the start-to-goal search and the goal-to-start search.\n",
    "\n",
    "This function will return the final search path, the set of nodes explored during the start-to-goal search, and the set of nodes explored during the goal-to-start search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bidirectional_a_star(graph, start, goal):\n",
    "    \"\"\"Run bidirectional uniform-cost search\n",
    "    between start and goal, and return the path,\n",
    "    the nodes explored from start-initial\n",
    "    search, and the nodes explored from the\n",
    "    goal-initial search.\"\"\"\n",
    "\n",
    "    from itertools import groupby\n",
    "\n",
    "    def remove_dups(lst):\n",
    "        return [k for k,items in groupby(lst)]\n",
    "\n",
    "    def getCost(graph, path):\n",
    "        cost = 0\n",
    "        prevNode = \"yolo\"\n",
    "        for i in path:\n",
    "            if prevNode == \"yolo\":\n",
    "                prevNode = i\n",
    "            else:\n",
    "                cost += graph.edge[prevNode][i]['weight']\n",
    "                prevNode = i\n",
    "        return cost\n",
    "\n",
    "    def getPath(child, goal, goal_paths):\n",
    "        if child == goal:\n",
    "            return []\n",
    "        path = [child]\n",
    "        while path[-1] != goal:\n",
    "            path.append(goal_paths[path[-1]])\n",
    "        return path\n",
    "\n",
    "    def heuristic(graph, u, v, goal):\n",
    "        return math.sqrt( (graph.node[goal]['position'][0] - graph.node[v]['position'][0])**2 +  (graph.node[goal]['position'][1] - graph.node[v]['position'][1])**2  )\n",
    "\n",
    "\n",
    "    def build_next_level(paths, frontier, explored, costIn, graph, goal):\n",
    "        p = copy.deepcopy(paths)\n",
    "        ex = copy.deepcopy(explored)\n",
    "        mf = copy.deepcopy(frontier)\n",
    "        cst = copy.deepcopy(costIn)\n",
    "\n",
    "        node, prty = mf.pop()\n",
    "\n",
    "        for child in graph.neighbors(node):\n",
    "            child_cost = cst[node] + graph.edge[node][child]['weight']\n",
    "\n",
    "            if child not in cst or child_cost < cst[child]:\n",
    "                cst[child] = child_cost\n",
    "                priority = child_cost + heuristic(graph, node, child, goal)\n",
    "                mf.put(priority, child)\n",
    "                p[child] = node\n",
    "\n",
    "        ex.append(node)\n",
    "        return p, mf, ex, cst\n",
    "\n",
    "    if start == goal:\n",
    "            return [],([],[])\n",
    "\n",
    "    #if they are neighbors\n",
    "    if graph.neighbors(start).__contains__(goal):\n",
    "        return [start,goal], ([start,goal],[goal,start])\n",
    "\n",
    "    middleNodes = []\n",
    "\n",
    "    startFrontier = PriorityQueue()\n",
    "    startFrontier.put(0,start) #priority, node\n",
    "    goalFrontier = PriorityQueue()\n",
    "    goalFrontier.put(0,goal)\n",
    "\n",
    "    start_paths = { start:None } # node:parent\n",
    "    goal_paths = { goal:None }\n",
    "\n",
    "    sCost = {start:0}\n",
    "    gCost = {goal:0}\n",
    "\n",
    "    sExplored = []\n",
    "    gExplored = []\n",
    "\n",
    "    while startFrontier.has_element() and goalFrontier.has_element():\n",
    "        # get shared nodes\n",
    "        middleNodes = list(set(sExplored) & set(gExplored))\n",
    "        if middleNodes: break\n",
    "\n",
    "        # build next level/depth decide on which to expand\n",
    "        sNode, sPriority = startFrontier.pop()\n",
    "        startFrontier.put(sPriority, sNode)\n",
    "        gNode, gPriority = goalFrontier.pop()\n",
    "        goalFrontier.put(gPriority, gNode)\n",
    "\n",
    "        if sCost[sNode] <= gCost[gNode]: #expand from start side\n",
    "            start_paths, startFrontier, sExplored, sCost= build_next_level(start_paths, startFrontier, sExplored, sCost, graph, goal)\n",
    "        else:\n",
    "            goal_paths, goalFrontier, gExplored, gCost = build_next_level(goal_paths, goalFrontier, gExplored, gCost, graph, goal)\n",
    "    else: # exited without break, empty path\n",
    "        return [],([],[])\n",
    "\n",
    "    # build the result\n",
    "\n",
    "    middle = list(middleNodes)[0]\n",
    "    #from middle to a\n",
    "    res = []\n",
    "    c = middle\n",
    "    while c != start:\n",
    "        c = start_paths[c]\n",
    "        res.insert(0,c)\n",
    "\n",
    "    res.append(middle)\n",
    "\n",
    "    #from middle to b\n",
    "    c = middle\n",
    "    while c != goal:\n",
    "        c = goal_paths[c]\n",
    "        res.append(c)\n",
    "\n",
    "    #look for shortcut\n",
    "    #res is original path\n",
    "    while startFrontier.has_element():\n",
    "        node, prty = startFrontier.pop()\n",
    "        if gExplored.__contains__(node):\n",
    "            tempPath = [start]\n",
    "            tempPath.extend(getPath(node, start, start_paths)[::-1])\n",
    "            tempPath.extend(getPath(node, goal,goal_paths))\n",
    "            tempPath = remove_dups(tempPath)\n",
    "            tempCost = getCost(graph, tempPath)\n",
    "            #Path ['h', 'u', 'b', 'f', 's'] is longer than an optimal path ['h', 'u', 'b', 'p', 'r', 's']\n",
    "            oCost = getCost(graph, remove_dups(res))\n",
    "            if tempCost < oCost:\n",
    "                res = tempPath\n",
    "\n",
    "    return res, (sExplored,gExplored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: Tridirectional search\n",
    "------\n",
    "20 points\n",
    "\n",
    "Implement tridirectional search in the naive way: starting from each goal node, perform a uniform-cost search and keep expanding until two of the three searches meet.\n",
    "\n",
    "This will return the path computed and the set of all nodes explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tridirectional_search(graph, goals):\n",
    "    \"\"\"Run tridirectional uniform-cost search\n",
    "    between the goals, and return the path \n",
    "    and the nodes explored.\"\"\"\n",
    "    if len(goals)!= len(set(goals)):\n",
    "        return [],[]\n",
    "    \n",
    "    paths = []    \n",
    "    frontier = copy.copy(goals)\n",
    "    explored = []\n",
    "    costs = {goals:0}\n",
    "    while frontier.has_element():\n",
    "        node = frontier.pop(0)\n",
    "        \n",
    "        if node in explored:\n",
    "            node2 = explored[explored.index(node)]\n",
    "            path = [node, node2, costs[node] + costs[node2]]\n",
    "            if (path not in paths):\n",
    "                paths.append(path)\n",
    "        \n",
    "        explored.append(node)\n",
    "        \n",
    "        if ((len(paths) == (len(goals))-1)):\n",
    "            break\n",
    "        \n",
    "        for edge in graph.edges(node):\n",
    "            child = edge[1]\n",
    "            if child not in explored:\n",
    "                costs[child] += distance(node, child)\n",
    "                if child not in frontier:\n",
    "                    frontier.append(child)\n",
    "                else:\n",
    "                    child2 = frontier[frontier.index(child)]\n",
    "                    if (costs[child] < costs[child2]):\n",
    "                        frontier[frontier.index(child)] = child\n",
    "        frontier = sorted(frontier, key=lambda x: x.cost)\n",
    "        \n",
    "    if ((len(paths) < (len(goals)-1))):\n",
    "        return [],[]\n",
    "    return paths, explored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4: Tridirectional search\n",
    "------\n",
    "15 points\n",
    "\n",
    "This is the heart of the assignment. Implement tridirectional search in such a way as to consistently improve on the performance of your previous implementation. This means consistently exploring fewer nodes during your search in order to reduce runtime.\n",
    "\n",
    "The specifics are up to you, but we have a few suggestions:\n",
    "- Tridirectional A*\n",
    "- choosing landmarks and precomputing reach values\n",
    "- ATL (A\\*, landmarks, and triangle-inequality)\n",
    "- shortcuts (skipping nodes with low reach values)\n",
    "\n",
    "This function will return the path computed and the set of all nodes explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tridirectional_search_advanced(graph, goals):\n",
    "    \"\"\"Run an improved tridirectional search between\n",
    "    goals, and return the path and nodes explored.\"\"\"\n",
    "    if len(goals)!= len(set(goals)):\n",
    "        return [],[]\n",
    "    \n",
    "    paths = []    \n",
    "    frontier = copy.copy(goals)\n",
    "    explored = []\n",
    "    costs = {goals:0}\n",
    "    while frontier.has_element():\n",
    "        node = frontier.pop(0)\n",
    "        \n",
    "        if node in explored:\n",
    "            node2 = explored[explored.index(node)]\n",
    "            path = [node, node2, costs[node] + costs[node2]]\n",
    "            if (path not in paths):\n",
    "                paths.append(path)\n",
    "        \n",
    "        explored.append(node)\n",
    "        \n",
    "        #Check if min paths found\n",
    "        if ((len(paths) == (len(goals))-1)):\n",
    "            break\n",
    "        \n",
    "        for edge in graph.edges(node):\n",
    "            child = edge[1]\n",
    "            if child not in explored:\n",
    "                costs[child] += distance(node, child)\n",
    "                if child not in frontier:\n",
    "                    frontier.append(child)\n",
    "                else:\n",
    "                    child2 = frontier[frontier.index(child)]\n",
    "                    if (costs[child] < costs[child2]):\n",
    "                        frontier[frontier.index(child)] = child\n",
    "        frontier = sorted(frontier, key=lambda x: x.cost)\n",
    "        \n",
    "    if ((len(paths) < (len(goals)-1))):\n",
    "        return [],[]\n",
    "    return paths, explored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Race!\n",
    "---\n",
    "Here's your chance to show us your best stuff. This part is mandatory if you want to compete in the race for extra credit. Implement custom_search() using whatever strategy you'd like. Remember that 'goals' will be a list of the three nodes between which you should route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_search(graph, goals):\n",
    "    \"\"\"Run your best tridirectional search between\n",
    "    goals, and return the path and nodes explored.\"\"\"\n",
    "    raise NotImplementedError\n",
    "    # return path, nodes_explored"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
